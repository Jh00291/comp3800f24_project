{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0af030a0-dc15-4061-be98-68bf14354d58",
   "metadata": {},
   "source": [
    "# Author: Jacob Haas\n",
    "Version: Comp3800 Fall 24\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05ea81a-c744-41f4-862d-c5f691ebd734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec19bf1a-e4a8-4a2f-b9ac-b4bd4e9882d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate keywords files\n",
    "\n",
    "output_file = \"comp3800f24_keywords.txt\"\n",
    "if not os.path.exists(output_file):\n",
    "    keywords_files = glob.glob(\"keywords/*.txt\")\n",
    "    with open(output_file, \"w\") as outfile:\n",
    "        for fname in keywords_files:\n",
    "            with open(fname) as infile:\n",
    "                outfile.write(infile.read() + \"\\n\")\n",
    "    print(f\"Keywords files concatenated into {output_file}.\")\n",
    "else:\n",
    "    print(f\"{output_file} already exists. Skipping file creation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7070f471-b693-4406-9d9d-6780c0094953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and clean the dataset\n",
    "\n",
    "tweets_df = pd.read_csv(\"comp3800f24_tweets.csv\", low_memory=False)\n",
    "tweets_df = tweets_df[tweets_df[\"type\"] == \"tweet\"]\n",
    "common_columns = [\n",
    "    \"id\", \"url\", \"twitterUrl\", \"text\", \"source\", \"retweetCount\",\n",
    "    \"replyCount\", \"likeCount\", \"quoteCount\", \"viewCount\",\n",
    "    \"createdAt\", \"lang\", \"bookmarkCount\", \"isReply\",\n",
    "    \"inReplyToId\", \"conversationId\", \"inReplyToUsername\",\n",
    "    \"isPinned\", \"isRetweet\", \"isConversationControlled\"\n",
    "]\n",
    "tweets_df = tweets_df[common_columns]\n",
    "print(\"Shape after loading the dataset:\", tweets_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8550b06-94ec-4928-9cd9-c70ea0c7cad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and preprocess text\n",
    "\n",
    "def clean_and_tokenize(text):\n",
    "    # Remove URLs, mentions, and special characters\n",
    "    text = re.sub(r'http\\S+|www\\S+|@\\S+', '', text)  # Remove URLs and mentions\n",
    "    text = re.sub(r'[^A-Za-z0-9\\s]', '', text)       # Remove special characters\n",
    "    text = text.lower()                              # Convert to lowercase\n",
    "    tokens = [word for word in text.split() if word not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "tweets_df[\"processed_text\"] = tweets_df[\"text\"].apply(clean_and_tokenize)\n",
    "\n",
    "# Combine all words into a single list\n",
    "all_words = [word for tokens in tweets_df[\"processed_text\"] for word in tokens]\n",
    "\n",
    "# Count word frequencies\n",
    "word_counts = Counter(all_words).most_common(20)\n",
    "print(word_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1acb45-c3e7-4eb1-9222-a2f517049b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(*zip(*word_counts))\n",
    "plt.xlabel(\"Words\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Most Frequent Words\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5f67a5-ff0d-441f-a703-051ae4a40ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment analysis\n",
    "tweets_df[\"sentiment\"] = tweets_df[\"text\"].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "tweets_df[[\"text\", \"sentiment\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5587db-1cb8-4f12-ab66-f1009f2616a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wordclouds for positive and negative tweets\n",
    "positive_text = \" \".join(tweets_df[tweets_df[\"sentiment\"] > 0][\"text\"])\n",
    "negative_text = \" \".join(tweets_df[tweets_df[\"sentiment\"] < 0][\"text\"])\n",
    "\n",
    "# Positive Wordcloud\n",
    "wordcloud_positive = WordCloud(width=800, height=400, background_color=\"white\").generate(positive_text)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud_positive, interpolation=\"bilinear\")\n",
    "plt.title(\"Positive Tweets Wordcloud\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# Negative Wordcloud\n",
    "wordcloud_negative = WordCloud(width=800, height=400, background_color=\"white\").generate(negative_text)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud_negative, interpolation=\"bilinear\")\n",
    "plt.title(\"Negative Tweets Wordcloud\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e3f27d-3cae-4574-8b1d-d205cf7d190d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'retweetCount' is numeric\n",
    "tweets_df[\"retweetCount\"] = pd.to_numeric(tweets_df[\"retweetCount\"], errors=\"coerce\")\n",
    "tweets_df = tweets_df.dropna(subset=[\"retweetCount\"])\n",
    "tweets_df[\"retweetCount\"] = tweets_df[\"retweetCount\"].astype(int)\n",
    "\n",
    "# Most retweeted tweets sentiment\n",
    "most_retweeted = tweets_df.nlargest(10, \"retweetCount\")\n",
    "\n",
    "# Shorten tweet text for better visualization\n",
    "most_retweeted[\"short_text\"] = most_retweeted[\"text\"].apply(lambda x: x[:50] + \"...\" if len(x) > 50 else x)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(most_retweeted[\"short_text\"], most_retweeted[\"sentiment\"], color=\"skyblue\", edgecolor=\"black\")\n",
    "plt.xlabel(\"Sentiment\", fontsize=12)\n",
    "plt.ylabel(\"Tweets\", fontsize=12)\n",
    "plt.title(\"Sentiment of Most Retweeted Tweets\", fontsize=16)\n",
    "plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# Adjust ticks and layout\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbb74e6-d653-4ea7-90b1-94363d920c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse datetime\n",
    "tweets_df[\"createdAt\"] = pd.to_datetime(tweets_df[\"createdAt\"])\n",
    "\n",
    "# Filter tweets with keywords\n",
    "subset = tweets_df[tweets_df[\"text\"].str.contains(\"X|Grok\", case=False, na=False)]\n",
    "\n",
    "# Sentiment over time\n",
    "subset[\"date\"] = subset[\"createdAt\"].dt.date\n",
    "sentiment_over_time = subset.groupby(\"date\")[\"sentiment\"].mean()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(sentiment_over_time.index, sentiment_over_time.values, label=\"Sentiment\", color=\"blue\")\n",
    "plt.axvline(pd.to_datetime(\"2022-04-14\"), color=\"red\", linestyle=\"--\", label=\"Twitter became X\")\n",
    "plt.axvline(pd.to_datetime(\"2024-10-15\"), color=\"green\", linestyle=\"--\", label=\"Grok Content Usage Announcement\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Average Sentiment\")\n",
    "plt.title(\"Sentiment Over Time Regarding 'X' and 'Grok'\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72135057-8b10-4070-a74b-d6890b93f8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize text data\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "text_features = vectorizer.fit_transform(tweets_df[\"text\"].fillna(\"\")).toarray()\n",
    "\n",
    "# PCA for dimensionality reduction\n",
    "pca = PCA(n_components=50)\n",
    "reduced_features = pca.fit_transform(text_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7c0b53-0db4-4258-8e11-1678e9b804a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict retweet count\n",
    "X = reduced_features\n",
    "y = tweets_df[\"retweetCount\"].fillna(0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3800)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
